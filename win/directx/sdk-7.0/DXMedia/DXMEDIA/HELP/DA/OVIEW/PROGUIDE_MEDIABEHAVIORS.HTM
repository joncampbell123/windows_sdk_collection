<!-- DOCTYPE HTML PUBLIC "-//IETF//DTD HTML//EN" -->

<HTML>
<HEAD><TITLE>Using Media Behaviors</TITLE>
<SCRIPT LANGUAGE="JavaScript"> var sRelPath = '../' </SCRIPT>


<META NAME="Description" CONTENT="Using Media Behaviors">
<META HTTP-EQUIV="Content-Type" CONTENT="text/html; CHARSET=iso8859-1">
<META NAME="MS.LOCALE" CONTENT="EN-US">
<META NAME="ROBOTS" CONTENT="all">

<!-- SNIFF_START -->

<SCRIPT LANGUAGE="JAVASCRIPT">
//<!--
var g_isIE = false, g_isNav = false, g_iMaj = 0, g_sPlat = "";
// -->

</SCRIPT>
<SCRIPT SRC="../ver.js"></SCRIPT>
<SCRIPT SRC="../gloss.js"></SCRIPT>


<SCRIPT DEFER SRC="../common.js"></SCRIPT>
<SCRIPT DEFER>
//<!--
function InitPage()
{
	if (g_isIE && g_iMaj >= 4)	
	{

		SetTOC();
	}
}
//-->

</SCRIPT>

<!-- STYLE_START -->

<SCRIPT LANGUAGE="JAVASCRIPT">
//<!--
   var sVR = '../'	// Set root for the style sheet
   var sCSS = '<LINK REL="stylesheet" HREF="' + sVR;

   if(g_isIE)
   {
	   if (g_iMaj >= 4) // For MSIE 4.0 or later
	   {
		   sCSS += 'dxm_basicSDKIE4';
		   if (g_sPlat == "Win") // Windows only for now
		   {
			   document.createStyleSheet(sVR + 'dxm_advSDKIE4.css');
		   }
	   }
	   else // For MSIE 3.0 or earlier
	   {
		   sCSS += 'dxm_basicSDKIE3';
	   }
   }
   else if (g_isNav) // For all Nav versions
   {
	   sCSS += 'dxm_basicSDKNAV';
   }
   else
   {
	   sCSS += 'dxm_basicSDKIE3'; // default to IE3 sheet
   }

   sCSS += (sCSS == '' ? '' : '.css" TYPE="text/css">');

   document.write(sCSS);
//-->

</SCRIPT>
<!-- STYLE_END -->


</HEAD>
<BODY onload="InitPage(); if (g_isIE && g_iMaj >= 4){HdgrphControl(); initGloss()}" BGCOLOR="#FFFFFF">
<A NAME="pagetop"></A><A NAME="Using_Media_Behaviors"></A>



<!-- HEADGRAPH_START -->

<TABLE CLASS="main" BORDER=0 CELLSPACING="0" CELLPADDING="0" WIDTH="*">
<TR>
<TD ROWSPAN="3" VALIGN="TOP" WIDTH="*">
<IMG SRC="../art/header1.gif" WIDTH="107" HEIGHT="110" BORDER=0 ALT="Using Media Behaviors"></TD>
<TD ROWSPAN="2" VALIGN="TOP" WIDTH="217">
<IMG SRC="../art/hdrdanim.gif" WIDTH="217" HEIGHT="110" BORDER=0 ALT="DirectAnimation Animated Header --Using Media Behaviors"></TD><TD VALIGN="TOP" WIDTH="383"><IMG SRC="../art/header3.gif" WIDTH="383" HEIGHT="95" BORDER=0 ALT="*">
</TD>
<TD VALIGN="TOP" WIDTH="100%">
<IMG SRC="../art/spacer1.gif" WIDTH="100%" HEIGHT="94" BORDER=0 ALT="Microsoft DirectAnimation SDK">
</TD>
</TR>
<!-- HEADGRAPH_END -->


<!-- DACONTROL_START -->

	<DIV ID="HeadGraphAnim"></DIV>
	<SCRIPT LANGUAGE="JAVASCRIPT">if((g_isIE == true) && (g_iMaj > 3)) {window.self.document.writeln('<SCR' + 'IPT SRC="../anim.js"></SCR' + 'IPT>')}</SCRIPT>
<!-- DACONTROL_END -->


<!-- NAV_LINKS_START -->


<TR><TD VALIGN="TOP"><PRE><IMG ID="TOC_" SRC="../art/yelbtn.gif" WIDTH="11" HEIGHT="11" ALIGN="MIDDLE" BORDER=0 ALT="*"><A STYLE="color:black;font-weight:bold" ID="TOC" HREF="../contents.htm">Contents</A>  <IMG SRC="../art/yelbtn.gif" WIDTH="11" HEIGHT="11" ALIGN="MIDDLE" BORDER=0 ALT="*"><A STYLE="color:black;font-weight:bold" HREF="../index.htm">Index</A>  <IMG SRC="../art/yelbtn.gif" WIDTH="11" HEIGHT="11" ALIGN="MIDDLE" BORDER=0 ALT="*"><A STYLE="color:black;font-weight:bold" HREF="proguide_oview.htm">Topic Contents</A>
</PRE></TD></TR>
<TR><TD COLSPAN="2" VALIGN="TOP"><PRE><IMG SRC="../art/yelbtn.gif" WIDTH="11" HEIGHT="11" ALIGN="MIDDLE" BORDER=0 ALT="*"><B>Previous Topic:</B> <A STYLE="color:black" HREF="proguide_basics.htm">The Basics</A>
<IMG SRC="../art/yelbtn.gif" WIDTH="11" HEIGHT="11" ALIGN="MIDDLE" BORDER=0 ALT="*"><B>Next Topic:</B> <A  STYLE="color:black" HREF="proguide_UsingBehaviors.htm">Using Behaviors</A>
</PRE></TD></TR></TABLE>
<!-- NAV_LINKS_END -->


<!-- START POP-UP GLOSSARY -->

<SCRIPT LANGUAGE="JAVASCRIPT">if((g_isIE == true) && (g_iMaj > 3)) {window.self.document.writeln('<SCR' + 'IPT SRC="../tip.js"></SCR' + 'IPT><IFRAME ID="G_L_S" NAME="SecretBuffer" STYLE="display: none" SRC=""></IFRAME>')}</SCRIPT>
<!-- END POP-UP GLOSSARY -->



<BLOCKQUOTE CLASS="body">

<!-- CONTENTS_START -->

<H1>Using Media Behaviors</H1>

<P>This section describes Microsoft&reg; DirectAnimation&#153; media behaviors and how to use them. Behaviors that are rendered for presentation to the user are called <I>media behaviors</I> and include two-dimensional (2-D) image behaviors (the <A HREF="../ref_script/class/DAImageClass.htm#DAImage_Class">DAImage</A> class and Java <A HREF="../ref_java/class/ImageBvr.htm#ImageBvr_Class">ImageBvr</A> class), three-dimensional (3-D) geometry behaviors (the <A HREF="../ref_script/class/DAGeometryClass.htm#DAGeometry_Class">DAGeometry</A> class and Java <A HREF="../ref_java/class/GeometryBvr.htm#GeometryBvr_Class">GeometryBvr</A> class), and <A CLASS="Glossary" HREF="javascript:Glossary(sRelPath + 'gloss/gloss_S.htm#sound')">sound</A> behaviors (the <A HREF="../ref_script/class/DASoundClass.htm#DASound_Class">DASound</A> class and Java <A HREF="../ref_java/class/SoundBvr.htm#SoundBvr_Class">SoundBvr</A> class). <A CLASS="Glossary" HREF="javascript:Glossary(sRelPath + 'gloss/gloss_T.htm#texture')">Textures</A> are also covered in this section since texturing often involves an <A CLASS="Glossary" HREF="javascript:Glossary(sRelPath + 'gloss/gloss_I.htm#image')">image</A> textured onto a <A CLASS="Glossary" HREF="javascript:Glossary(sRelPath + 'gloss/gloss_G.htm#geometry')">geometry</A>.
<P>This section contains the following topics:
<UL><LI><A HREF="proguide_MediaBehaviors.htm#Using_Images">Using Images</A>
<LI><A HREF="proguide_MediaBehaviors.htm#Using_Geometries">Using Geometries</A>
<LI><A HREF="proguide_MediaBehaviors.htm#Rendering_Geometries_into_Images">Rendering Geometries into Images</A>
<LI><A HREF="proguide_MediaBehaviors.htm#Applying_Textures">Applying Textures</A>
<LI><A HREF="proguide_MediaBehaviors.htm#Sound_basics">Using Sound</A>
</UL>
<H2><A NAME="Using_Images">Using Images</A></H2>
<P>DirectAnimation can construct or import 2-D images (<A HREF="../ref_script/class/DAImageClass.htm#DAImage_Class">DAImage</A> objects or Java <A HREF="../ref_java/class/ImageBvr.htm#ImageBvr_Class">ImageBvr</A> objects), and can perform sequences of operations on any source of animated images in any order. This section discusses the following topics.
<UL><LI><A HREF="proguide_MediaBehaviors.htm#Empty_Images">Empty Images</A>
<LI><A HREF="proguide_MediaBehaviors.htm#Constructing_Images">Constructing Images</A>
<LI><A HREF="proguide_MediaBehaviors.htm#Operations_on_Images">Operations on Images</A>
</UL>
<A NAME="Empty_Images"></A><P><B>Empty Images</B>
<P>DirectAnimation has two types of empty images. An <A HREF="../ref_script/dastaticproperties/DAImageObjects.htm#emptyv_i">EmptyImage</A> is the null image. It is transparent and undetectable. A <A HREF="../ref_script/dastaticproperties/DAImageObjects.htm#detectablev_i">DetectableEmptyImage</A> has infinite extent &#8212; that is, it extends throughout the entire view &#8212; and is transparent and detectable throughout its extent. The <B>DetectableEmptyImage</B> is useful for specifying hot spots in certain images. An image is said to be tangible at a certain point if it is either detectable or nontransparent at that point. Otherwise, the image at that point is said to be nontangible. 


<A NAME="Constructing_Images"></A><P><B>Constructing Images</B>
<P>The following approaches can be used to construct 2-D images:

<UL><LI>Importing bitmaps from GIF, JPEG, and BMP formats. 
<LI>Drawing lines and polygons. 
<LI>Rendering 3-D geometry into an image.
<LI>Rendering text into an image. 
<LI>Creating polygons with potentially animated <A CLASS="Glossary" HREF="javascript:Glossary(sRelPath + 'gloss/gloss_C.htm#color')">colors</A> at the vertices and smooth color interpolation between vertices (gradient fills). 
<LI>Combining two images.
<LI>Giving images an explicit Z-order in montages.
</UL>
<P>This section includes the following:
<UL><LI><A HREF="proguide_MediaBehaviors.htm#PG_Importing_Images">Importing Images</A>
<LI><A HREF="proguide_MediaBehaviors.htm#PG_Creating_Images">Creating Images</A>
</UL>
<A NAME="PG_Importing_Images"></A><P><B>Importing Images</B>
<P>A basic way to create images is to import bitmaps represented in commonly used formats. This provides good leverage from the many image-authoring tools that currently exist. 

<P>The following JScript code shows how to import an image:
<PRE>
 mediaBase = "..\\..\\..\\..\\media\\";
 imgBase = mediaBase + "image\\";
 myImage = m.ImportImage(imgBase + "bird.gif");
</PRE>
<P>The following Java code shows how to import an image: 

<PRE>
   //Create a URL base
   URL imageBase = buildURL(getImportBase(),"file:/c:/DxM/Media/image");
   // Create an image behavior by importing an image file
   ImageBvr img = importImage(buildURL(imageBase, "picture.jpg"));
</PRE>
<P>DirectAnimation supports the importation of bitmaps in the .jpg, .gif, and .bmp formats. The string reference to the image can be any valid URL. Importing an image has the following results:

<UL><LI>The bitmap is imported and returned to the user as a behavior of type <A HREF="../ref_script/class/DAImageClass.htm#DAImage_Class">DAImage</A> (or the Java type <A HREF="../ref_java/class/ImageBvr.htm#ImageBvr_Class">ImageBvr</A>). 
<LI>The image is centered on the origin (0,0). 
<LI>Only the bitmap portion of the image is detectable. 
<LI>When displayed, the image will map to the display window in a one-to-one pixel correspondence with the bitmap in the file from which it was read. This is true provided the image has not been scaled, sheared, or rotated, although translations are acceptable. 
<LI>A bounding-box (which you can extract with the <A HREF="../ref_script/class/DAImageClass.htm#boundingBoxv_i">BoundingBox</A> function or Java <A HREF="../ref_java/class/ImageBvr.htm#boundingBox_i">boundingBox</A> method) surrounds the tangible region of the image and is measured in meters. 
</UL>
<P>The relationship between pixels and meters changes depending on the display resolution. While one display might have a ratio of 18,000 pixels per meter, another display might have a ratio of 22,000 per meter. This means that the <A CLASS="Glossary" HREF="javascript:Glossary(sRelPath + 'gloss/gloss_B.htm#bounding_box')">bounding box</A> returned for an imported image varies depending on the specific display resolution. 

<P>There are ways to work around the device dependency of imported bitmaps. They involve scaling the bitmap in a device-dependent way so that the resultant image size is of some fixed, desired value across the different device resolutions. See 
<A HREF="proguide_basics.htm#Meter_Based_Space">Meter-Based Space</A> for a description.

<A NAME="PG_Creating_Images"></A><P><B>Creating Images</B>
<P>You can create several kinds of 2-D images: solid color, lines, text, geometric images, gradient filled images, and montages. For a discussion of geometric images, see <A HREF="proguide_MediaBehaviors.htm#Using_Geometries">Using Geometries</A>.
<P>This section discusses the following:
<UL><LI><A HREF="proguide_MediaBehaviors.htm#PG_Hatch_Filled">Hatch Filled Boxes</A>
<LI><A HREF="proguide_MediaBehaviors.htm#PG_Text">Text</A>
<LI><A HREF="proguide_MediaBehaviors.htm#PG_Gradient_Fill">Gradient Fill Images</A>
<LI><A HREF="proguide_MediaBehaviors.htm#PG_Rendering_Geo">Rendering Geometry into an Image</A>
<LI><A HREF="proguide_MediaBehaviors.htm#PG_Montages">Montages</A>
</UL>
<P>One of the simplest images to construct is a solid color image, as shown in the following example. 

<PRE>
&#009;im = m.solidColorImage(m.Blue);
</PRE>
<P>This results in an infinite-extent image with the <A HREF="../ref_script/class/DAColorClass.htm#DAColor_Class">DAColor</A> behavior <A HREF="../ref_script/dastaticproperties/DAColorObjects.htm#bluev_color">Blue</A>. Typically, such an image is <A CLASS="Glossary" HREF="javascript:Glossary(sRelPath + 'gloss/gloss_C.htm#crop')">cropped</A> or clipped before being used. Solid color images are commonly used to obtain solid-colored polygons or as viewport backgrounds, where the color can be time-varying. 


<A NAME="PG_Hatch_Filled"></A><P><B>Hatch Filled Boxes</B>
<P>You can also construct images by creating hatch marks in boxes, as shown in the following example with <A HREF="../ref_script/dastaticfunctions/DAImageObjects.htm#hatchcv_i">HatchCross</A>:
<PRE>
   im = m.HatchCross(m.Green, 0.2);

</PRE>
<A NAME="PG_Text"></A><P><B>Text</B>
<P>You can construct images by rendering text, as shown in the following example with <A HREF="../ref_script/dastaticfunctions/DAImageObjects.htm#stringImageanv_i">StringImageAnim</A> and <A HREF="../ref_script/dastaticfunctions/DAImageObjects.htm#stringImagev_i">StringImage</A>: 

<PRE>
  myText = "This is the default font style.";
  defaultFS = m.DefaultFont;
  myTextImage = m.StringImage(myText, defaultFS);
</PRE>
<P>The text, which can have attributes such as font type, color, and style (bold or italic), is rendered into an image with its extent centered on the origin. By default, the text's color is black, its font family is Times-Roman, its size is 12 points, and it is neither bold nor italic. 
<P>You can set the text attributes and where the text is displayed. The following code sample renders bold, red text to the screen centered on position <I>posX</I>, <I>posY</I>.


<PRE>
   im = m.TextImage("Hello, World!", m.Font("Arial", 10, m.Red).Bold;
   im2 = im.Transform(m.Translate2(posX, posY));
</PRE>
<A NAME="PG_Gradient_Fill"></A><P><B>Gradient Fill Images</B>
<P>Gradient fills provide a very compact form of color images, where regions are filled with smoothly interpolated colors between specified colors at given vertices. For example, you can construct an image from a gradient-filled square, as shown in the following example with <A HREF="../ref_script/dastaticfunctions/DAImageObjects.htm#gradientSquarev_i">GradientSquare</A>: 
<PRE>
   im = m.GradientSquare(m.Red, m.Green, m.Blue, m.Yellow);
</PRE>
<P>You can obtain the most general form of a gradient fill through the <A HREF="../ref_script/class/DAStaticsClass.htm#DAStatics_Class">DAStatics</A> function <A HREF="../ref_script/dastaticfunctions/DAImageObjects.htm#gradientPolygonv_i">GradientPolygon</A>(<I>pts, colors</I>), which specifies an array of points and a corresponding array of colors. The arrays specify a triangular mesh with one color per vertex. The resultant image is based on a linear interpolation of the colors across each triangle in the RGB color space. Although interpolation in other color spaces might be desired, DirectAnimation maps this CPU-intensive operation to hardware, which currently performs the interpolation only in RGB.

<P>Other more specialized forms of gradient fills, which are essentially shortcuts based on the general form described in this section, include the following <A HREF="../ref_script/class/DAStaticsClass.htm#DAStatics_Class">DAStatics</A> methods: 

<UL><LI><A HREF="../ref_script/dastaticfunctions/DAImageObjects.htm#gradientSquarev_i">GradientSquare</A>(<I>color1, color2, color3, color4</I>), which generates a unit square centered on the origin and with dimensions of 1 unit. The four colors are averaged into a color at the intersection of the diagonals, and then the four triangles delineated by the diagonals have their vertex colors interpolated. 

<LI><A HREF="../ref_script/dastaticfunctions/DAImageObjects.htm#grhoranv_i">GradientHorizontalAnim</A>(<I>start, stop, power</I>)and <A HREF="../ref_script/dastaticfunctions/DAImageObjects.htm#grhorv_i">GradientHorizontal</A>(<I>start, stop, power</I>), which create an image that smoothly interpolates between the start and stop colors. Colors start on the left and go toward the right, based on the power specified by power. 
</UL>
<A NAME="PG_Rendering_Geo"></A><P><B>Rendering Geometry into an Image</B>
<P>You can construct 2-D images by rendering 3-D images (geometries) into two dimensions, as shown in the following example. 

<PRE>
   Geo = m.ImportGeometry("cube.x");
   Camera =  m.PerspectiveCamera(projPointNum, maxZNum);
   Img = Geo.Render(Camera);

</PRE>
<P>Note that the <I>Camera</I> parameters must be calculated from the size of the geometry and the display viewport.


<A NAME="PG_Montages"></A><P><B>Montages</B>
<P>An image can be the rendering of a montage (<A HREF="../ref_script/class/DAMontageClass.htm#DAMontage_Class">DAMontage</A>) object which consists of a group of <A HREF="../ref_script/class/DAImageClass.htm#DAImage_Class">DAImage</A> objects, each with a number that indicates its z-order in the list. The <A HREF="../ref_script/dastaticfunctions/DAMontageObjects.htm#imageMontagev_mont">ImageMontage</A>(<I>Image, z-order</I>) and 
<A HREF="../ref_script/dastaticfunctions/DAMontageObjects.htm#imageMontageanv_mont">ImageMontageAnim</A>(<I>Image, z-order</I>) functions can be used to add images to a montage. The z-order determines how the images will <A CLASS="Glossary" HREF="javascript:Glossary(sRelPath + 'gloss/gloss_O.htm#overlay')">overlay</A> each other. Images with larger z-values are always on top (in front) of images with smaller z-values. If the z-order number is animated (a <A HREF="../ref_script/class/DANumberClass.htm#DANumber_Class">DANumber</A> object), the order in which the images are layered changes with time. Montages are ideal for situations where the layering of the different images is dynamic. 


<A NAME="Operations_on_Images"></A><P><B>Operations on Images</B>
<P>DirectAnimation operations can generate new and more complex images from given images. Also, some of these operations generate useful data, such as the bounding-box around a given image. 

<P>The operations for composing animated 2-D images include the following: 

<UL><LI>Overlaying animated images. 
<LI>Polygonal clipping of animated images. 
<LI>Transformations such as scale, rotate, shear, and translate. 
<LI>Animated tiling of animated images into a larger animated image. 
<LI>Applying an animated transparency to an animated image.
<LI>Applying an animated image as an animated texture map. 
<LI>Creating a 2-D animation along a <A CLASS="Glossary" HREF="javascript:Glossary(sRelPath + 'gloss/gloss_S.htm#spline')">spline</A>. 
</UL>
<P>You can perform any sequence of the above operations on any source of animated images in any order.


<A NAME="Transformations"></A><P><B>Transformations</B>
<P>You can obtain a transformed version of an image by applying the <A HREF="../ref_script/class/DAImageClass.htm#transformv_i">Transform</A>(<I>xf</I>)method, where <I>xf</I> is of type <A HREF="../ref_script/class/DATransform2Class.htm#DATransform2_Class">DATransform2</A> and can be an arbitrary 2-D affine transform. The <B>DATransform2</B> type has operations for constructing scales, translations, rotations, and shears from basic parameters such as <A HREF="../ref_script/class/DANumberClass.htm#DANumber_Class">DANumber</A> objects and <A HREF="../ref_script/class/DAVector2Class.htm#DAVector2_Class">DAVector2</A> objects. You also can construct transforms based on 2 by 3 matrices. Additional operations can compose transforms, obtain their inverses, and check whether they are singular. 

<P>You can use combinations of time-varying shears, scales, and translations to construct animation from a single image, for example, to move a <A CLASS="Glossary" HREF="javascript:Glossary(sRelPath + 'gloss/gloss_S.htm#sprite')">sprite</A> over a background image. 

<H2><A NAME="Using_Geometries">Using Geometries</A></H2>
<P>In DirectAnimation, you can construct or import 3-D graphics (<A HREF="../ref_script/class/DAGeometryClass.htm#DAGeometry_Class">DAGeometry</A> objects), and perform sequences of operations on any source of animated images in any order.

<P>This section discusses the following topics:
<UL><LI><A HREF="proguide_MediaBehaviors.htm#Constructing_Geometries">Constructing Geometries</A>
<LI><A HREF="proguide_MediaBehaviors.htm#Operations_on_Geometries">Operations on Geometries</A>
</UL>
<A NAME="Constructing_Geometries"></A><P><B>Constructing Geometries</B>
<P>The simplest way to construct a geometry behavior is to import a geometry from a .X formatted file by using <A HREF="../ref_script/dastaticfunctions/DAGeometryObjects.htm#importGeometryav_g">ImportGeometryAsync</A> or <A HREF="../ref_script/dastaticfunctions/DAGeometryObjects.htm#importGeometryv_g">ImportGeometry</A>(<I>URL</I>). You can also augment geometry with <A CLASS="Glossary" HREF="javascript:Glossary(sRelPath + 'gloss/gloss_L.htm#light')">lights</A>, including ambient, directional, point, and spot lights. You can attach a sound source to a geometry, which is used to give 3-D spatial characteristics to a sound by embedding it in other geometric models. Finally, <A HREF="../ref_script/dastaticproperties/DAGeometryObjects.htm#emptyv_geo">EmptyGeometry</A> is a constant of the <A HREF="../ref_java/class/GeometryBvr.htm#GeometryBvr_Class">GeometryBvr</A> type and is empty. 

<P><A HREF="../ref_script/class/DAGeometryClass.htm#DAGeometry_Class">DAGeometry</A> objects (and Java <A HREF="../ref_java/class/GeometryBvr.htm#GeometryBvr_Class">GeometryBvr</A> objects)can be: 
<UL><LI>Given an <A CLASS="Glossary" HREF="javascript:Glossary(sRelPath + 'gloss/gloss_O.htm#opacity')">opacity</A> attribute. 
<LI>Textured with an image. 
<LI>Given diffuse attributes with color parameters. 
</UL>
<P>All of these attributes can vary with time. 


<A NAME="Operations_on_Geometries"></A><P><B>Operations on Geometries</B>
<P>The operations for composing 3-D geometric animations include: 

<UL><LI>Aggregating animated 3-D geometry. You can combine two geometry values with the <A HREF="../ref_java/staticmethods/GeometryBvrObjects.htm#union_g">union</A> operation. 
<LI>Applying animated images as animated textures. 
<LI>Applying animated transparency and color attributes. 
<LI>Applying transformations such as scale, rotate, shear, and translate. 
<LI>Applying projection with animated perspective or parallel <A CLASS="Glossary" HREF="javascript:Glossary(sRelPath + 'gloss/gloss_C.htm#camera')">cameras</A> to an animated image. 
<LI>Animating 3-D attributes using splines (B-spline format). 
</UL>
<P>You can perform any sequence of the preceding operations on any source of animated geometry in any order. 


<H2><A NAME="Rendering_Geometries_into_Images" IDX_CONCEPT="NOINDEX; Rendering Geometries into Images;">Rendering Geometries into Images</A></H2>
<P>DirectAnimation uses a camera to project a 3-D model (a <A HREF="../ref_script/class/DAGeometryClass.htm#DAGeometry_Class">DAGeometry</A> object) into a 2-D image (an <A HREF="../ref_script/class/DAImageClass.htm#DAImage_Class">DAImage</A> object) with the <B>DAGeometry</B> function <A HREF="../ref_java/class/GeometryBvr.htm#rendercam_g">render</A>. 

<P>Using Direct3-D as the underlying 3-D mechanism, the <A HREF="../ref_script/class/DAGeometryClass.htm#rendercamv_g">Render</A> operation renders/projects a geometry through a camera. 

<P>DirectAnimation supports two cameras: the <A HREF="../ref_script/dastaticfunctions/DACameraObjects.htm#perspectiveCameraanv_cam">PerspectiveCameraAnim</A> (and <A HREF="../ref_script/dastaticfunctions/DACameraObjects.htm#perspectiveCamerav_cam">PerspectiveCamera</A>) type for perspective projection, and the <A HREF="../ref_script/dastaticfunctions/DACameraObjects.htm#parallelCameraanv_cam">ParallelCameraAnim</A> (and <A HREF="../ref_script/dastaticfunctions/DACameraObjects.htm#parallelCamerav_cam">ParallelCamera</A>) type for parallel projection.

<P>These cameras consist of the following three elements: 

<UL><LI>The image plane, which is the XY plane. 
<LI>A near <A CLASS="Glossary" HREF="javascript:Glossary(sRelPath + 'gloss/gloss_C.htm#clip')">clip</A> plane that is parallel to the XY plane. 
<LI>A projection point for <A HREF="../ref_script/dastaticfunctions/DACameraObjects.htm#perspectiveCamerav_cam">PerspectiveCamera</A> that lies on the z-axis, and a projection direction for <A HREF="../ref_script/dastaticfunctions/DACameraObjects.htm#parallelCamerav_cam">ParallelCamera</A>) that is in the z-direction. 

</UL>
<P>Rendering involves projecting the geometry located on the side of the near plane opposite the projection point into an image on the image plane. The resultant image extends infinitely. If you are interested in only a section of the image, you must use 2-D operations such as <A HREF="../ref_script/class/DAImageClass.htm#cropv_i">Crop</A> or <A HREF="../ref_script/class/DAImageClass.htm#clipv_i">Clip</A> on the image to extract that section. 
<P>The following figure shows the relationship between the projection point, the near clip plane, and the image plane.

<P><IMG SRC="../art/implane.gif" WIDTH="533" HEIGHT="268" ALT="Projection"> 

<P>DirectAnimation cameras have an origin at (0,0,0) that can be transformed. Such transformations affect the placement of the projection point, the near clip plane, and the image plane. You can use translation and rotation for positioning the camera relative to the geometric model being projected. 

<P>You can use the x- and y- scales to zoom in or out in relation to the rendered model. Increasing the XY scale results in a zoom out (the rendered image shrinks), while decreasing the XY scale results in a zoom in (the rendered image grows). Control the perspective effect by changing the distance of the projection point along the positive z-axis in relation to the origin (that is, the image plane). The closer the projection point is to the projected object, the more pronounced the perspective effect becomes. 


<H2><A NAME="Applying_Textures">Applying Textures</A></H2>
<P>Just as you can project a 3-D object (a <A HREF="../ref_script/class/DAGeometryClass.htm#DAGeometry_Class">DAGeometry</A> object) as a 2-D image (a <A HREF="../ref_script/class/DAImageClass.htm#DAImage_Class">DAImage</A> object) through a camera, you can apply a 2-D image as a texture to a 3-D object through texture mapping. 

<P>The <A HREF="../ref_script/class/DAGeometryClass.htm#DAGeometry_Class">DAGeometry</A> <A HREF="../ref_script/class/DAGeometryClass.htm#textureImagev_g">TextureImage</A> function takes an image and an existing geometry, and returns a geometry textured with that image. Because images and geometries are such rich data types, this simple texture method is extremely powerful. The following example shows how to apply a texture to an imported sphere.

<PRE>
    Geo = m.ImportGeometry("sphere.x");
    Marble = m.ImportImage("image/marble.jpg"));
    MarbledSphere =  Geo.TextureImage(Marble);
</PRE>
<P>Often a geometry is constructed by importing an existing geometry file. These files usually have 2-D texture coordinates associated with the vertices, generally ranging from (0,0) to (1,1). When these geometries are texture-mapped with images, the texture coordinates are mapped to the identical image coordinates. 

<P>Thus, texture map coordinates of (0.3, 0.7) in the geometry map directly to the (0.3, 0.7) point in texture image coordinate space. 

<P>The correspondence between texture coordinate systems and image coordinate systems is simple, but also powerful and flexible. Consider the task of making an image wiggle along the first dimension as a texture on a cube. You can achieve this by texture mapping a horizontally wiggling image onto a static cube, as shown in the following example. 

<PRE>
   WiggleTexture = OrigTexture.Transform(m.Translate2(m.Sin(m.LocalTime), 0));
   NewCube = OldCube.TextureImage(WiggleTexture);
</PRE>
<P>If you want to infinitely <A CLASS="Glossary" HREF="javascript:Glossary(sRelPath + 'gloss/gloss_T.htm#tile')">tile</A> a small texture onto a geometry, you can create a tiled image using the <A HREF="../ref_script/class/DAImageClass.htm#DAImage_Class">DAImage</A> <A HREF="../ref_script/class/DAImageClass.htm#tilev_i">Tile</A> function, then use that resultant image as a texture. 

<H2><A NAME="Sound_basics">Using Sound</A></H2>
<P>The <A HREF="../ref_script/class/DASoundClass.htm#DASound_Class">DASound</A> object and the Java <A HREF="../ref_java/class/SoundBvr.htm#SoundBvr_Class">SoundBvr</A> behavior class implement sound in DirectAnimation. You can import sound from many audio formats, including WAV, MIDI, and MP2 files, or synthesize sound using built-in synthesizer sound sources. You can mix different sounds even if they originated from files of different audio formats. You can also spatialize sound by embedding sounds in 3-D objects and rendering them with a microphone (<A HREF="../ref_script/class/DAMicrophoneClass.htm#DAMicrophone_Class">DAMicrophone</A> or <A HREF="../ref_java/class/MicrophoneBvr.htm#MicrophoneBvr_Class">MicrophoneBvr</A>). 

<P>Currently, up to two channels are supported for sound in DirectAnimation. Sound also has infinite resolution, and each sound wave is continuous which means that in the abstract model there are no discrete sample values. 

<P>This section gives an overview of the following topics:
<UL><LI><A HREF="proguide_MediaBehaviors.htm#Constructing_Sound">Constructing Sound</A>
<LI><A HREF="proguide_MediaBehaviors.htm#Operations_on_Sound">Operations on Sound</A>
<LI><A HREF="proguide_MediaBehaviors.htm#Sound_Layering_Technique">Sound Layering Technique</A>
</UL>
<A NAME="Constructing_Sound"></A><P><B>Constructing Sound</B>
<P>You can import sound from a file in the WAV, MIDI, and MP2 formats with the <A HREF="../ref_script/class/DAStaticsClass.htm#DAStatics_Class">DAStatics</A> functions <A HREF="../ref_script/dastaticfunctions/DASoundObjects.htm#importSoundv_snd">ImportSound</A> and <A HREF="../ref_script/dastaticfunctions/DASoundObjects.htm#importSoundav_snd">ImportSoundAsync</A>, or with the Java method <A HREF="../ref_java/staticmethods/SoundBvrObjects.htm#importSound_snd">importSound</A>.
<P>For example, to import and play a sound in JScript, you can use the following code:
<PRE>
  m = DAControl.PixelLibrary;
  mySound = m.ImportSound("file://c:/dxmedia/media/sound/clock1.mp2").Sound;
  DAControl.Sound = mySound.Loop();
</PRE>
<P>The <A HREF="../ref_script/dastaticfunctions/DASoundObjects.htm#importSoundv_snd">ImportSound</A> function returns a <A HREF="../ref_script/class/DAImportationResultClass.htm#DAImportationResult_Class">DAImportationResult</A> object. To return a <A HREF="../ref_script/class/DASoundClass.htm#DASound_Class">DASound</A> object you access the <A HREF="../ref_script/class/DAImportationResultClass.htm#sndv_impr">Sound</A> property of the <B>DAImportationResult</B> object by appending ".Sound". 

<P>If you use the Java <A HREF="../ref_java/class/SoundBvr.htm#SoundBvr_Class">SoundBvr</A> method <A HREF="../ref_java/staticmethods/SoundBvrObjects.htm#importSound_snd">importSound</A>(<I>URL</I>, <I>length</I>), the length of the imported sound, in seconds, is returned as the <I>length</I> parameter. For example:
<PRE>
URL soundBase = buildURL(getImportBase(), "file:/c:/dxmedia/media/sound/");
NumberBvr length[] = new NumberBvr[1];
SoundBvr snd = importSound(buildURL(soundBase,"earth.wav"), length);
</PRE>
<P>You can then use the <I>length</I> parameter as follows:
<PRE>
SoundBvr twoSounds = (SoundBvr)until(snd, timer(length[0]), anotherSound);
</PRE>
<P>If you are not interested in the length, you can set the length to NULL. 


<P>DirectAnimation currently has an internal standard for audio format.


 The format is a dynamic range of 16 bits and a sampling rate of of 22,050 Hz. For best results, you should import audio files with this format because DirectAnimation will convert the files to its internal standard, which may result in degradation if the files are not in the same format.

<P>You can also synthesize sound. As an example, you can mix multiple sine waves. Each sine wave can have different attributes, so the resulting mix can produce many diverse sounds. The <A HREF="../ref_script/class/DAStaticsClass.htm#DAStatics_Class">DAStatics</A> property and <A HREF="../ref_java/class/SoundBvr.htm#SoundBvr_Class">SoundBvr</A> type <A HREF="../ref_java/staticfields/SoundBvrObjects.htm#sinSynth_snd">sinSynth</A> represents a constant tone. The <A HREF="../ref_java/staticfields/SoundBvrObjects.htm#silence_snd">silence</A> property and type represents complete silence. By default, <B>sinSynth</B> produces a 1 Hz tone which is subaudible, so you need to increase the frequency. For example, the following JScript code produces a tone:
<PRE>
 sndMidC = m.SinSynth.Rate(440);
</PRE>
<P>The following Java code also produces a tone.
<PRE>
SoundBvr sndMidC = sinSynth.rate(toBvr(440));
</PRE>
<A NAME="Operations_on_Sound"></A><P><B>Operations on Sound</B>
<P>You can obtain new sounds from other sounds by modifying sound parameters or by mixing. In DirectAnimation, the <A HREF="../ref_script/class/DASoundClass.htm#DASound_Class">DASound</A> class functions <A HREF="../ref_script/class/DASoundClass.htm#loopv_snd">Loop()</A>, <A HREF="../ref_script/class/DASoundClass.htm#gainanv_snd">GainAnim</A> and <A HREF="../ref_script/class/DASoundClass.htm#gainv_snd">Gain</A>, <A HREF="../ref_script/class/DASoundClass.htm#rateanv_snd">RateAnim</A> and <A HREF="../ref_script/class/DASoundClass.htm#ratev_snd">Rate</A>, <A HREF="../ref_script/class/DASoundClass.htm#phaseanv_snd">PhaseAnim</A> and <A HREF="../ref_script/class/DASoundClass.htm#phasev_snd">Phase</A>, <A HREF="../ref_script/class/DASoundClass.htm#pananv_snd">PanAnim</A> and <A HREF="../ref_script/class/DASoundClass.htm#panv_snd">Pan</A> (and the Java <A HREF="../ref_java/class/SoundBvr.htm#SoundBvr_Class">SoundBvr</A> methods <A HREF="../ref_java/class/SoundBvr.htm#loop_snd">loop</A>, <A HREF="../ref_java/class/SoundBvr.htm#gain_snd">gain</A>, <A HREF="../ref_java/class/SoundBvr.htm#rate_snd">rate</A>, <A HREF="../ref_java/class/SoundBvr.htm#phase_snd">phase</A>, and <A HREF="../ref_java/class/SoundBvr.htm#pan_snd">pan</A>, and the <A HREF="../ref_script/class/DAStaticsClass.htm#DAStatics_Class">DAStatics</A> <A HREF="../ref_script/dastaticfunctions/DASoundObjects.htm#mixv_snd">Mix</A> function, allow creation of complex-sounding animations with few operations.

<P>The <A HREF="../ref_script/class/DASoundClass.htm#loopv_snd">Loop()</A> function takes a sound and repeats it continuously. If you have a sound whose composition changes with an event or user interaction and you tell the sound to loop, it will loop on its individual parts, not on the composition. For example, assume you have a sound that is <I>sound1</I> until the left mouse button is pressed, and then becomes <I>sound2</I>, and you loop this composite sound, as shown in the following JScript code:
<PRE>
snd =  m.Until(sound1, m.LeftButtonDown, sound2);
loopsnd= snd.Loop();
</PRE>
<P>The resulting sound is a continuous loop of <I>sound1</I> until the left mouse button is pressed, then becomes a continuous loop of <I>sound2</I>. It does not loop the composite behavior in that it does not loop <I>sound1</I> until the button is pressed, then cycle through <I>sound2</I> once, then go back to playing <I>sound1</I> until the button is pressed again.

<P>The <A HREF="../ref_script/class/DASoundClass.htm#gainv_snd">Gain</A> (volume) function scales the amplitude of the sound wave. The <A HREF="../ref_script/class/DASoundClass.htm#ratev_snd">Rate</A> function changes the rate of sample playback; for digital audio and synthesized sounds, this scales the frequency and changes the pitch. For audio in MIDI format, this changes the tempo. The <A HREF="../ref_script/class/DASoundClass.htm#gainanv_snd">GainAnim</A>, and <A HREF="../ref_script/class/DASoundClass.htm#rateanv_snd">RateAnim</A> parameters are animated.

<p>The <A HREF="../ref_script/class/DASoundClass.htm#pananv_snd">PanAnim</A> and <A HREF="../ref_script/class/DASoundClass.htm#panv_snd">Pan</A> (balance) functions vary the gain in the left and right channels of a stereo sound. Consider the following JScript panning sample. This sample draws a red circle that moves in a straight line. The pan parameter varies with the position of a moving ball. To view the sample, click on the "Show Sample" button; to view source code, click on the "Show Sample Code" button. 

<!--***********************Panning Sample**********************-->

<P><B>Pan Sample</B>
<P><BR>

<INPUT TYPE=BUTTON VALUE="Show Sample" STYLE="width:150" ID=btnStart_pan OnClick="start_pan()"><BR>
<DIV ID="controlDiv_pan" align="center"> &nbsp; </DIV>
<P><BR>
<INPUT TYPE=BUTTON VALUE="Show Sample Code" STYLE="width:150" ID=btnShowCode_pan OnClick="ShowHideCode_pan()"><BR>
<PRE><DIV ID="dispSourceCode_pan"></DIV></PRE>

<SCRIPT LANGUAGE="JavaScript">
  var FlagNotStarted_pan = true;
  var FlagSCNotVisible_pan = true;
  var DACONTROL_pan = '<OBJECT ID="DAViewer_pan" STYLE="width:600;height:150;z-index: -1" \n'+
'CLASSID="CLSID:B6FFC24C-7E13-11D0-9B47-00C04FC2F51D"> \n'+
'</OBJECT> ';
 
function CreateDA_pan() {
	controlDiv_pan.innerHTML = DACONTROL_pan;
}

function start_pan(){
   if (FlagNotStarted_pan){
   	CreateDA_pan();
	runthis_pan();
	show_pan();
    }
    else {
    	hide_pan();
    }
}

function show_pan(){
	FlagNotStarted_pan = false;
	btnStart_pan.value="Hide Sample";
	btnShowCode_pan.style.display='';
}
function hide_pan(){
	FlagNotStarted_pan=true;
	controlDiv_pan.innerHTML = '';
	btnStart_pan.value="Show Sample";
	controlDiv_pan.innerHTML = '';
}
function ShowHideCode_pan(){
	if (FlagSCNotVisible_pan){
		dispSourceCode_pan.innerText = DACONTROL_pan + '\n' + DAScript_pan.innerHTML;
		FlagSCNotVisible_pan = false;
		btnShowCode_pan.value = "Hide Sample Code";
	}
	else{
		dispSourceCode_pan.innerText = '';
		FlagSCNotVisible_pan = true;
		btnShowCode_pan.value = "Show Sample Code";
	}
}

</SCRIPT>
<P><BR> 
<!--***********************Panning Sample**********************-->

<p> The <A HREF="../ref_script/class/DASoundClass.htm#phaseanv_snd">PhaseAnim</A> and <A HREF="../ref_script/class/DASoundClass.htm#phasev_snd">Phase</A> functions shift the point in the sound cycle where the sound starts (all sound is cyclic except pure white noise). For positive phase values, the sound starts later in the sound cycle. For negative values, the sound starts earlier in the sound cycle. 
<p>Consider the following phase sample. This sample lets you enter different phase values for a sound dynamically as it plays back. You can set the sound to loop by clicking the "Loop" box. If you click the "Mix" box, the sound with the phase offset and the original sound with no phase offset are mixed together. This sometimes makes it easier to hear the effect of the phase shift. This sample is a combination of VBScript and JScript. To see the source code, click the right-mouse button while the mouse is over the sample, and choose <B>View Source</B> from the menu that appears.
<P><B>Phase Sample</B>
<P><BR>

<center><iframe name="exampleframe" src="MonsterPhaseDemo.htm"
height=600 width=600 align=center FRAMEBORDER=20 FRAMESPACING=5
scrolling="no">
</iframe></center>


<P>You can perform any sequence of the preceding operations, phase, pan, rate, and so on, on any source of animated sounds in any order.
<P>You can mimic sound effects by using these <A HREF="../ref_script/class/DASoundClass.htm#DASound_Class">DASound</A> functions and <A HREF="../ref_java/class/SoundBvr.htm#SoundBvr_Class">SoundBvr</A> methods. For example, you can vary the distance between a moving sound source and a listener, by varying the parameter of <A HREF="../ref_script/class/DASoundClass.htm#gainanv_snd">GainAnim</A>. However, you can achieve much more realistic effects by embedding sounds in a geometry. This also relieves you of the overhead of tracking relative positions and modifying sounds yourself. For example, the following JScript code embeds the sound <I>Snd</I> in the geometry <I>Geo</I>:
<PRE>
//Get the sound and the geometry.
Snd = m.ImportSound("bird.wav").Sound;
Geo = m.ImportGeometry("sphere.x");

//Embed the sound in a blank geometry.
GeoSound = m.SoundSource(Snd);

//Join the sound with the desired geometry.
GeoWithSound= m.UnionGeometry(Geo, GeoSound);

//Create a microphone at the origin.
Mic = m.DefaultMicrophone;

//Move the microphone somewhere else.
Mic2 = Mic.Transform(m.Translate3(5, 4, 5); 

//Render the geometric sound.
AmbSound = GeoWithSound.RenderSound(mic2);
</PRE>
<A NAME="Pan"></A><P><B>Pan</B>
<P>The <A HREF="../ref_script/class/DASoundClass.htm#pananv_snd">PanAnim</A> and <A HREF="../ref_script/class/DASoundClass.htm#panv_snd">Pan</A> functions and <A HREF="../ref_java/class/SoundBvr.htm#pan_snd">pan</A> Java method take a sound and move the energy between the left and right channels according to a pan parameter. 

The pan parameter varies between &shy;1 and +1. In the stereo case, negative values of the pan parameter increase the energy sent to the left channel and decrease the energy sent to the right channel. Positive values of the pan parameter increase the energy sent to the right channel and decrease the energy sent to the left channel. A value of 0 balances the energy between the two channels.


<A NAME="Gain"></A><P><B>Gain</B>
<P>When authoring sounds in DirectAnimation you should use the full 16-bit dynamic range to provide the best resolution, then use the <A HREF="../ref_script/class/DASoundClass.htm#gainv_snd">Gain</A> function or Java <A HREF="../ref_java/class/SoundBvr.htm#gain_snd">gain</A> method to scale the volume of the sounds in your animation. 
<P>For example, the following JScript code varies the gain by the the sin of <A HREF="../ref_script/dastaticproperties/DANumberObjects.htm#LocalTimev_num">LocalTime</A>:
<PRE>
 DAControl.Sound = mySound.Loop().GainAnim(m.Sin(m.LocalTime));
</PRE>
<P>DirectAnimation assumes all sounds have been normalized to use the full 16-bit dynamic range. Consequently, all sounds seem equally loud. For example, a jet plane and a whisper will sound as though they are the same volume. Sounds can be prescaled with the <A HREF="../ref_script/class/DASoundClass.htm#gainv_snd">Gain</A> function. Because there is no way to change the actual gain of a personal computer's amplifier, sounds can only be attenuated. Attenuating a sound is the same as multiplying it by a value between 0 and 1. 

<P>In the following Java example, two sounds, which are heard in the left and right channels respectively, will have an equal volume, even though their gains are 1 and 5 because the gain is clamped at 1: 
<PRE>
    URL soundBase = buildURL(getImportBase(), "file:/c:/DxM/Media/sound/");
    SoundBvr snd1 = importSound(buildURL(soundBase, "seagull.wav"), null);
    SoundBvr snd2 = importSound(buildURL(soundBase, "surf.wav"), null);
&#009;setSound( mix( 
&#009;&#009;snd1.gain( toBvr( 1  ) ).pan( toBvr( -1 ) ),
&#009;&#009;snd2.gain( toBvr( 5 ) ).pan( toBvr( 1 ) ) ) );
</PRE>
<P>In the following example, the sound in the left channel is louder than the sound in the right channel because their gains are 1 and 0.2: 

<PRE>
&#009;&#009;setSound(mix(
&#009;&#009;snd1.gain(toBvr(1)).pan(toBvr(-1)),
&#009;&#009;snd2.gain(toBvr(0.2)).pan(toBvr(1))));
</PRE>
<P>When sounds are embedded in a geometry and spatialized (using the Java <A HREF="../ref_java/class/GeometryBvr.htm#GeometryBvr_Class">GeometryBvr</A> method <A HREF="../ref_java/staticmethods/GeometryBvrObjects.htm#soundSource_g">soundSource</A> and a <A HREF="../ref_java/class/MicrophoneBvr.htm#MicrophoneBvr_Class">MicrophoneBvr</A>), even though gains greater than 1 do not produce louder sounds, they do produce sounds that can be heard at a greater distance by increasing the spatial volume that is at maximum sound (for example, a small sphere of maximum sound or a large sphere of maximum sound).

<P>In particular, loud sounds such as a jet engine should be scaled by a gain greater than 1. Unlike sounds in the real world, the sound only becomes louder as you approach until the gain equals 1. Once this limit is reached, there is no more amplification, and the sound's volume remains constant regardless of how close you get to the source of the sound. 

<P>The following diagram shows that, for gains larger than 1, the volume is clamped at 1. 
<P><IMG SRC="../art/gain2.gif" WIDTH="158" HEIGHT="120" ALT="Distance vs. gain of 2">



<A NAME="Mix"></A><P><B>Mix</B>
<P>The <A HREF="../ref_script/class/DAStaticsClass.htm#DAStatics_Class">DAStatics</A> <A HREF="../ref_script/dastaticfunctions/DASoundObjects.htm#mixv_snd">Mix</A> function and the Java <A HREF="../ref_java/staticmethods/SoundBvrObjects.htm#mix_snd">mix</A> method merge two sound waves into one by adding the corresponding waves. You can mix any sounds, even if they originated from different audio formats. If mixing produces an overflow value, the result is clamped. 


<A NAME="Sound_Layering_Technique"></A><P><B>Sound Layering Technique</B>
<P>The operations provided by DirectAnimation on <A HREF="../ref_script/class/DASoundClass.htm#DASound_Class">DASound</A> objects (and Java <A HREF="../ref_java/class/SoundBvr.htm#SoundBvr_Class">SoundBvr</A> objects) enable the generation of dynamic high-quality synthetic sounds from basic sound seeds by parameterization and layering (or mixing). These sounds can be always fresh and responsive to the action in the animation.
<P>Traditionally, people have authored loops of compressed sounds for ambient noise. This reduces the size of the audio needed but also produces boring sounds, because a loop soon starts to sound repetitive and unrealistic. With DirectAnimation, you can produce much more realistic sounds, for example, a wave sound that amplifies only when the wave actually breaks on the shore in your animation, a seagull cry that follows the motion of the seagull across the viewport, and wind levels that can be controlled by user interaction (see the Lighthouse sample in DXMedia\Samples\Multimedia\DAnim\Java\Showcase\Lighthouse.html). 

<P>You create synthetic sounds by modifying seed sounds with parameters that are random or are related to your animation. These parameters are usually time-varying. You then mix the results together in a way suitable to your animation. Thus, sound can be as flexibly and synthetically generated as 3-D models are. Simple parts are transformed, colored, or textured and then combined together into more interesting models. 

<P>For example, the <A HREF="../ref_script/dastaticproperties/DASoundObjects.htm#sinSynthv_snd">SinSynth</A> function produces a sine-wave based sound, which can be given a variety of attributes to create a diverse set of synthetically generated sound waves. The Lighthouse sample in DXMedia\Samples\Multimedia\DAnim\Java\Showcase\Lighthouse.html generates an ocean ambient sound modified by the weather condition parameter. The weather condition parameter is controlled by the user with the slider controls. The Lighthouse sample demonstrates two basic techniques for creating sound. One is the generation of parameterized cyclic sounds and the other is the generation of random periodic sounds (the latter has a silent period between the successive occurrences). 

<!-- CONTENTS_END -->

<!-- START_PAGE_FOOTER -->


<H6><HR size=1></H6>
<P><A Class="line" HREF="#pagetop"><IMG src="../art/arrowup1.gif" WIDTH="11" HEIGHT="11" ALIGN="MIDDLE" BORDER=0 ALT="Top of Page">&nbsp;Top of Page</A>
<BR><A Class="line" HREF="../../cpyright.htm">&#169; 1998 Microsoft Corporation. All rights reserved. Terms of Use.</A>
<!-- END_PAGE_FOOTER -->

<!--***********************Panning Sample**********************-->

<SPAN ID="DAScript_pan">
<SCRIPT LANGUAGE="JavaScript">
<!--
 function runthis_pan()

 
   {
   l=DAViewer_pan.PixelLibrary;

   // Construct a red circle
   fill=l.SolidColorImage(l.Red);

   // Draw a circle. A circle is an oval whose radius along the x-axis is the same
   // as its radius along the y-axis
   ovalImg=l.Oval(50, 50).Fill(l.DefaultLineStyle, fill);

   // Construct a straight path that the circle will travel along
   startingPoint=l.Point2(-150, 50);
   endingPoint=l.Point2(150, 50);
   myPath=l.Line(startingPoint, endingPoint);

   // Tell the circle to  go to the starting point and wait 2 seconds
   goToStart=l.Translate2Point(startingPoint).Duration(2);

   // Tell the circle to follow myPath and go from the beginning to end in 10 seconds. 
   followRoute=l.FollowPath(myPath, 10);

    // Combine the two circle instructions. 
   combineMovements=l.Sequence(goToStart, followRoute);

   // Transform the static drawing of a circle into one that moves along a path.
   movingCircle=ovalImg.Transform(combineMovements);

   // Put the circle's position in xArr and use the position to control the
   //pan factor panFac
   posPt2=l.Origin2.Transform(combineMovements);
   xArr=new Array(movingCircle, posPt2);
   dim=150;              // in pixels
   dimMeters=l.mul(l.DANumber(dim), l.Pixel);
   panFac=l.Div(xArr[1].X, dimMeters); 

  // import a sound file
  mySound=l.ImportSound("clock1.mp2").Sound;

  // Loop the imported sound with the position-varying pan for 12 seconds.
  DAViewer_pan.Sound=l.Until(mySound.Loop().PanAnim(panFac),l.Timer(12),l.Silence);     
     
   
   // Now tell the DAViewer what image to display (our moving circle)
   DAViewer_pan.Image=movingCircle;

   // Finally, give it the go-ahead
   DAViewer_pan.Start();
 }
 
//-->

</script>

</SPAN>
<!--***********************Panning Sample**********************-->

</BLOCKQUOTE>
</BODY>
</HTML>
